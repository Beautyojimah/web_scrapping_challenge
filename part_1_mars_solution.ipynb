{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43fdca18-c40b-4bc5-8469-6097eea624c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f18daaa9-55f7-4c46-9a25-e520cfafb547",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c8067ea-f609-4751-9c6e-15aa79bb3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# Specify the path to ChromeDriver\n",
    "webdriver_service = Service(r'C:\\Users\\Beaut\\OneDrive\\Desktop\\drivers\\chromedriver.exe')\n",
    "driver = webdriver.Chrome(service=webdriver_service)\n",
    "\n",
    "# Visit the Mars news site\n",
    "url = 'https://static.bc-edx.com/data/web/mars_news/index.html'\n",
    "driver.get(url)\n",
    "\n",
    "# Here you can add more commands to interact with the page\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0cce8",
   "metadata": {},
   "source": [
    "# Create a Beautiful Soup object and use it to extract text elements from the website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6608d904-dc36-4314-b698-4be8a3d3ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Beautiful Soup object\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser').text\n",
    "\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818014b-b9f7-4a26-843d-586fc6839e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title_tags = soup.find_all('div', class_='content_title')\n",
    "preview_tags = soup.find_all('div', class_='article_teaser_body')\n",
    "\n",
    "# Check if the number of title tags and teaser tags are equal\n",
    "if len(title_tags) != len(preview_tags):\n",
    "    print('Mismatch in number of titles and teasers.')\n",
    "else:\n",
    "    articles = []\n",
    "    for title_tag, preview_tag in zip(title_tags, preview_tags):\n",
    "        title = title_tag.get_text().strip()\n",
    "        preview = preview_tag.get_text().strip()\n",
    "        \n",
    "        # Store the title and teaser in a dictionary, and append to list\n",
    "        articles.append({\n",
    "            'title': title,\n",
    "            'preview': preview\n",
    "        })\n",
    "\n",
    "# Now `articles` is a list of dictionaries, where each dictionary has a 'title' and 'preview'\n",
    "print(articles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724f19d-4cce-48af-8822-1f5bdaac0fdf",
   "metadata": {},
   "source": [
    "# Part 2: Scrape and Analyze Mars Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "555944b0-8c3c-4bc3-b4c2-40a915261cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()  # This will close the browser window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a31517-5064-4603-b452-4b4939dec919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
